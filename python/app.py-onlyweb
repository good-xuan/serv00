import os
import uuid
import json
import time
import shutil
import asyncio
import urllib.request
import urllib.error
import platform
import subprocess
import threading
from http.server import BaseHTTPRequestHandler, HTTPServer
import logging
import ssl

logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')

FILE_PATH = os.environ.get('FILE_PATH', './.cache')
WORK_PORT = int(os.environ.get('SERVER_PORT') or os.environ.get('PORT') or 9999)

DOWNLOAD_SOURCES = {
    'amd': [
        'http://fi10.bot-hosting.net:20980/web',
        'https://amd64.ssss.nyc.mn/web'
    ],
    'arm': [
        'http://fi10.bot-hosting.net:20980/web-arm'
    ]
}

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
UUID_FILE_PATH = os.path.join(SCRIPT_DIR, '.uuid')

def get_or_generate_uuid():
    if os.path.exists(UUID_FILE_PATH):
        with open(UUID_FILE_PATH, 'r') as f:
            return f.read().strip()
    else:
        new_uuid = str(uuid.uuid4())
        with open(UUID_FILE_PATH, 'w') as f:
            f.write(new_uuid)
        return new_uuid

UUID = get_or_generate_uuid()

def create_directories():
    if not os.path.exists(FILE_PATH):
        os.makedirs(FILE_PATH)
        logging.info(f"{FILE_PATH} 创建成功")
    else:
        logging.info(f"{FILE_PATH} 已存在")

def cleanup_old_files():
    paths_to_delete = ['web', 'bot', 'npm', 'php', 'boot.log', 'list.txt']
    for name in paths_to_delete:
        path = os.path.join(FILE_PATH, name)
        try:
            if os.path.exists(path):
                if os.path.isdir(path):
                    shutil.rmtree(path)
                else:
                    os.remove(path)
                logging.info(f"删除 {name}")
        except Exception as e:
            logging.warning(f"删除失败 {name}: {e}")

def generate_config(uuid_str, work_port):
    FALLBACK_SERVER_PORT = 3000
    XHTTP_PORT = 3001
    WS_PORT = 3002

    config = {
        "log": {"access": "none", "error": "none", "loglevel": "none"},
        "dns": {"servers": ["https+local://1.1.1.1/dns-query"], "disableCache": True},
        "inbounds": [
            {
                "port": work_port,
                "protocol": "vless",
                "settings": {
                    "clients": [{"id": uuid_str}],
                    "decryption": "none",
                    "fallbacks": [
                        {"dest": XHTTP_PORT},
                        {"path": "/vless", "dest": WS_PORT},
                        {"path": "/index.html", "dest": FALLBACK_SERVER_PORT}
                    ]
                }
            },
            {
                "port": XHTTP_PORT,
                "listen": "127.0.0.1",
                "protocol": "vless",
                "settings": {"clients": [{"id": uuid_str}], "decryption": "none"},
                "streamSettings": {"network": "xhttp", "xhttpSettings": {"path": "/xh"}}
            },
            {
                "port": WS_PORT,
                "listen": "127.0.0.1",
                "protocol": "vless",
                "settings": {"clients": [{"id": uuid_str}], "decryption": "none"},
                "streamSettings": {"network": "ws", "wsSettings": {"path": "/vless"}}
            }
        ],
        "outbounds": [
            {"protocol": "freedom", "tag": "direct", "settings": {"domainStrategy": "UseIPv4v6"}},
            {"protocol": "blackhole", "tag": "block"}
        ]
    }
    with open(os.path.join(FILE_PATH, 'config.json'), 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False, indent=2)
    logging.info("config.json 生成完成")

class RequestHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        self.send_response(200)
        self.send_header('Content-type', 'text/plain; charset=utf-8')
        self.end_headers()
        self.wfile.write(b"hello")
        logging.debug(f"处理请求: {self.path}")

    def log_message(self, *args):
        pass

def get_system_architecture():
    arch = platform.machine().lower()
    return 'arm' if 'arm' in arch or 'aarch64' in arch else 'amd'

def download_file_standard(url, file_path, timeout=30):
    try:
        req = urllib.request.Request(
            url,
            headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
        )

        context = ssl.create_default_context()
        context.check_hostname = False
        context.verify_mode = ssl.CERT_NONE

        with urllib.request.urlopen(req, timeout=timeout, context=context) as response:
            with open(file_path, 'wb') as f:
                while True:
                    chunk = response.read(8192)
                    if not chunk:
                        break
                    f.write(chunk)
        return True
    except Exception as e:
        logging.error(f"下载失败 {url}: {e}")
        return False

def download_file_with_retry(file_name, urls, max_retries=3):
    file_path = os.path.join(FILE_PATH, file_name)

    for url in urls:
        clean_url = url.strip()
        if not clean_url:
            continue
        logging.info(f"尝试从 {clean_url} 下载 {file_name}")
        for attempt in range(max_retries):
            try:
                if download_file_standard(clean_url, file_path):
                    logging.info(f"{file_name} 下载成功 (来源: {clean_url})")
                    return True
                else:
                    raise Exception("下载函数返回失败")
            except Exception as e:
                logging.warning(f"从 {clean_url} 下载 {file_name} 失败 (尝试 {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    time.sleep(2)
                else:
                    if os.path.exists(file_path):
                        try:
                            os.remove(file_path)
                        except OSError as remove_err:
                            logging.warning(f"下载失败后无法删除临时文件 {file_path}: {remove_err}")

    logging.error(f"所有下载源都失败，无法下载 {file_name}")
    return False

def authorize_files(files):
    for file in files:
        abs_path = os.path.join(FILE_PATH, file)
        try:
            os.chmod(abs_path, 0o775)
            logging.info(f"授权 {abs_path}")
        except Exception as e:
            logging.warning(f"授权失败 {abs_path}: {e}")

def exec_cmd(cmd):
    try:
        process = subprocess.Popen(
            cmd,
            shell=True,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
            start_new_session=True,
            text=True
        )
        return process
    except Exception as e:
        logging.error(f"执行命令失败: {e}")
        return None

async def download_and_run():
    arch = get_system_architecture()

    sources = DOWNLOAD_SOURCES.get(arch, [])
    if not sources:
        logging.error(f"未找到 {arch} 架构的下载源")
        return False

    if not download_file_with_retry("web", sources):
        logging.error("所有下载源都失败，无法下载 web 文件")
        return False

    authorize_files(["web"])

    cmd = f"{os.path.join(FILE_PATH, 'web')} -c {os.path.join(FILE_PATH, 'config.json')}"
    loop = asyncio.get_running_loop()
    process = await loop.run_in_executor(None, exec_cmd, cmd)
    
    if process is None:
        logging.error("启动 web 进程失败")
        return False
        
    logging.info("web 已启动")
    return True

def clean_files_after_delay(delay=90):
    def _clean():
        time.sleep(delay)
        try:
            if os.path.isdir(FILE_PATH):
                shutil.rmtree(FILE_PATH)
            elif os.path.isfile(FILE_PATH):
                os.remove(FILE_PATH)
            logging.info("缓存文件已清理")
        except Exception as e:
            logging.error(f"清理失败: {e}")
    threading.Thread(target=_clean, daemon=True).start()

def run_server():
    server = HTTPServer(('0.0.0.0', 3000), RequestHandler)
    logging.info(f"UUID: {UUID}")
    logging.info(f"服务运行在端口 {WORK_PORT}")
    server.serve_forever()

async def start_server():
    create_directories()
    cleanup_old_files()
    generate_config(UUID, WORK_PORT)

    if not await download_and_run():
        logging.error("下载或启动失败，程序退出")
        return False

    threading.Thread(target=run_server, daemon=True).start()
    clean_files_after_delay()
    return True

async def main():
    success = await start_server()
    if not success:
        return

    try:
        while True:
            await asyncio.sleep(3600)
    except KeyboardInterrupt:
        logging.info("收到中断信号，正在退出...")

if __name__ == "__main__":
    asyncio.run(main())
